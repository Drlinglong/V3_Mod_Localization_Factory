#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æä¿®å¤åçš„BAè¯å…¸
"""

import json
from collections import defaultdict

def analyze_glossary(file_path):
    """åˆ†æè¯å…¸æ–‡ä»¶"""
    
    print("ğŸ” åˆ†æBAè¯å…¸...")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print("âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # åŸºæœ¬ä¿¡æ¯
        metadata = data.get('metadata', {})
        print(f"\nğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
        print(f"   - åç§°: {metadata.get('name', 'N/A')}")
        print(f"   - ç‰ˆæœ¬: {metadata.get('version', 'N/A')}")
        print(f"   - æœ€åæ›´æ–°: {metadata.get('last_updated', 'N/A')}")
        print(f"   - æ¸¸æˆID: {metadata.get('game_id', 'N/A')}")
        
        # è¯æ¡ç»Ÿè®¡
        entries = data.get('entries', [])
        total_entries = len(entries)
        print(f"\nğŸ“Š è¯æ¡ç»Ÿè®¡:")
        print(f"   - æ€»è¯æ¡æ•°: {total_entries}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        categories = defaultdict(int)
        for entry in entries:
            category = entry.get('metadata', {}).get('category', 'unknown')
            categories[category] += 1
        
        print(f"\nğŸ“‚ æŒ‰ç±»åˆ«ç»Ÿè®¡:")
        for category, count in sorted(categories.items()):
            percentage = (count / total_entries) * 100
            print(f"   - {category}: {count} ({percentage:.1f}%)")
        
        # æŒ‰è¯æ€§ç»Ÿè®¡
        parts_of_speech = defaultdict(int)
        for entry in entries:
            pos = entry.get('metadata', {}).get('part_of_speech', 'unknown')
            parts_of_speech[pos] += 1
        
        print(f"\nğŸ”¤ æŒ‰è¯æ€§ç»Ÿè®¡:")
        for pos, count in sorted(parts_of_speech.items()):
            percentage = (count / total_entries) * 100
            print(f"   - {pos}: {count} ({percentage:.1f}%)")
        
        # ç¼©å†™å’Œå˜ä½“ç»Ÿè®¡
        has_abbreviations = 0
        has_variants = 0
        for entry in entries:
            if entry.get('abbreviations'):
                has_abbreviations += 1
            if entry.get('variants'):
                has_variants += 1
        
        print(f"\nğŸ”— ç‰¹æ®Šå­—æ®µç»Ÿè®¡:")
        print(f"   - æœ‰ç¼©å†™çš„è¯æ¡: {has_abbreviations} ({has_abbreviations/total_entries*100:.1f}%)")
        print(f"   - æœ‰å˜ä½“çš„è¯æ¡: {has_variants} ({has_variants/total_entries*100:.1f}%)")
        
        # è¯­è¨€è¦†ç›–ç»Ÿè®¡
        languages = defaultdict(int)
        for entry in entries:
            translations = entry.get('translations', {})
            for lang in translations.keys():
                languages[lang] += 1
        
        print(f"\nğŸŒ è¯­è¨€è¦†ç›–ç»Ÿè®¡:")
        for lang, count in sorted(languages.items()):
            percentage = (count / total_entries) * 100
            print(f"   - {lang}: {count} ({percentage:.1f}%)")
        
        # ç¤ºä¾‹è¯æ¡
        print(f"\nğŸ“ ç¤ºä¾‹è¯æ¡:")
        for i, entry in enumerate(entries[:3]):
            print(f"   {i+1}. {entry.get('id', 'N/A')}")
            print(f"      - è‹±æ–‡: {entry.get('translations', {}).get('en', 'N/A')}")
            print(f"      - ä¸­æ–‡: {entry.get('translations', {}).get('zh-CN', 'N/A')}")
            print(f"      - ç±»åˆ«: {entry.get('metadata', {}).get('category', 'N/A')}")
            print()
        
        return total_entries
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return 0

def main():
    """ä¸»å‡½æ•°"""
    file_path = "data/glossary/stellaris/blue_archive_fixed.json"
    
    try:
        total_entries = analyze_glossary(file_path)
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ˆ è¯å…¸åŒ…å« {total_entries} ä¸ªæœ‰æ•ˆè¯æ¡")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()

