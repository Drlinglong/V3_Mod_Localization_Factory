# 多文件并行处理实现总结

## 🎯 任务目标

本项目旨在通过实现批次级全局并行调度，彻底解决传统文件处理中存在的阻塞问题，从而显著提升Mod本地化的效率和用户体验。

## ❌ 原有问题回顾

在引入当前并行架构之前，项目面临的主要挑战是：

*   **文件级别串行**：翻译过程是文件一个接一个地进行处理，即使单个文件内部可以并行处理批次，但整体效率受限于文件间的串行执行。
*   **批次级别并行受限**：虽然单个文件内的文本可以被分割成批次并提交给AI进行并行翻译，但这种并行仅限于单个文件内部。
*   **资源浪费**：当存在大量文件时，即使配置了多个并行线程，大部分线程也可能处于空闲状态，等待当前文件处理完毕。例如，如果有24个并行线程，但只能同时运行1个文件的1个批次，其他23个线程就会被浪费。

## ✅ 解决方案：批次级全局并行调度

本项目通过引入全新的 `ParallelProcessor` 架构，实现了**批次级全局并行调度**，其核心思想是将所有待处理文件的所有文本批次视为一个统一的任务池，并进行并行处理。

### 1. 核心组件与数据结构

*   **`FileTask`**：文件任务数据结构，封装了单个文件的所有必要信息，包括文件名、原始文本行、待翻译文本列表、键值映射、语言配置、游戏配置、Mod上下文、AI服务提供商名称、输出路径以及AI客户端实例等。
*   **`BatchTask`**：批次任务数据结构，封装了单个批次翻译所需的信息，包括所属的 `FileTask`、批次在文件中的索引、文本的起始/结束索引以及实际待翻译的文本列表。
*   **`ParallelProcessor`**：并行处理器主类，负责整个并行调度流程的编排和执行。

### 2. 调度流程详解

`ParallelProcessor` 的核心方法 `process_files_parallel` 负责协调整个并行翻译过程：

1.  **任务分解 (`_create_batch_tasks`)**：
    *   `ParallelProcessor` 首先遍历所有 `FileTask`。
    *   对于每个文件，根据其待翻译文本量和配置的 `CHUNK_SIZE`（批次大小），将其文本分割成多个 `BatchTask`。
    *   **动态批次大小**：`CHUNK_SIZE` 可以根据不同的AI服务提供商进行动态调整。例如，对于 `gemini_cli`，可能会使用更大的 `CHUNK_SIZE` (`GEMINI_CLI_CHUNK_SIZE`) 来优化CLI调用的开销和性能。
    *   每个 `BatchTask` 会被分配一个全局唯一的索引，以便后续结果收集。

2.  **全局批次并行处理 (`_process_batches_parallel`)**：
    *   `ParallelProcessor` 使用 `concurrent.futures.ThreadPoolExecutor` 创建一个线程池，其大小由 `max_workers` 参数决定。
    *   所有生成的 `BatchTask` 都被提交到这个线程池中，实现**真正的全局并行**。这意味着来自不同文件的批次可以同时在不同的线程中进行翻译。
    *   `concurrent.futures.as_completed` 用于异步收集已完成的批次结果。

3.  **批次翻译执行 (`_process_single_batch`)**：
    *   线程池中的每个工作线程会调用 `_process_single_batch` 来处理一个 `BatchTask`。
    *   `_process_single_batch` 会调用传入的 `translation_function`（通常是AI服务处理器的 `translate_texts_in_batches` 方法）来执行实际的翻译。
    *   **AI服务处理器职责**：AI服务处理器（如 `gemini_handler.py`）专注于与特定AI服务的交互，包括构建详细的prompt（注入上下文、词典术语、标点转换提示、游戏特定格式化规则）、调用API、解析响应以及处理重试逻辑。**重要的是，AI服务处理器内部通常是串行处理单个批次的文本，避免了嵌套线程池的复杂性。**
    *   **容错机制**：如果单个批次翻译失败（例如API错误、网络问题、AI响应格式不匹配），`_process_single_batch` 会返回 `None`。此时，`_process_batches_parallel` 会捕获此失败，并使用该批次的原始文本作为回退，确保整个翻译流程不会中断。

4.  **结果收集与文件重建 (`_collect_file_results`)**：
    *   当所有批次任务完成后，`ParallelProcessor` 会按文件对所有批次结果进行收集和排序。
    *   它会检查每个文件的翻译结果是否完整。如果某个文件的部分批次使用了回退文本，或者结果数量不匹配，则该文件的翻译结果将使用其原始文本作为回退，以保证数据的完整性。
    *   最终，每个文件的完整翻译结果（或回退后的原始文本）被组装起来。

### 3. 性能提升

通过这种批次级全局并行架构，项目实现了显著的性能提升：

*   **加速比**：在测试中，相较于旧的串行架构，实现了高达 **5.52倍** 的加速比。
*   **效率提升**：整体效率提升了 **451.7%**。
*   **资源利用率**：从仅能利用1/24的线程资源（单个文件串行处理）提升到可以同时利用14/24的线程资源（所有批次并行处理），充分发挥了多核CPU和网络带宽的潜力。

### 4. 架构优势

*   **高效率**：显著缩短了处理大量Mod文件所需的总时间。
*   **高稳定性**：强大的容错机制确保了即使部分AI请求失败，整个翻译任务也能平稳进行，并提供可用的结果。
*   **可扩展性**：易于集成新的AI服务提供商。只需实现符合 `translation_function` 接口的AI服务处理器即可。
*   **高质量翻译**：通过精细的prompt工程（上下文、词典、格式化规则），确保AI翻译的准确性和游戏术语的一致性。
*   **职责清晰**：调度逻辑与AI交互逻辑分离，提高了代码的可维护性和可读性。

## 🔧 技术实现细节

*   **Python `concurrent.futures.ThreadPoolExecutor`**：作为实现并行处理的核心工具。
*   **动态 `CHUNK_SIZE`**：通过 `scripts/config.py` 中的 `CHUNK_SIZE` 和 `GEMINI_CLI_CHUNK_SIZE` 进行配置，并在 `_create_batch_tasks` 中根据 `provider_name` 动态选择。
*   **重试机制**：AI服务处理器（如 `gemini_handler.py` 中的 `_translate_chunk`）内置了重试逻辑，以应对临时的网络波动或API错误。
*   **Prompt 工程**：`gemini_handler.py` 展示了如何构建复杂的prompt，包括：
    *   `base_prompt`：基本翻译指令。
    *   `context_prompt_part`：Mod主题上下文。
    *   `glossary_prompt_part`：动态注入的游戏术语词典。
    *   `punctuation_prompt_part`：智能生成的标点符号转换提示。
    *   `format_prompt_part`：游戏特定的格式化规则，确保翻译结果符合游戏文件格式。
*   **AI思考功能**：`gemini_handler.py` 支持根据配置启用或禁用Gemini的“思考功能”（`thinking_config`），以平衡翻译质量和成本。

## 总结

本项目通过精心设计的批次级全局并行调度架构，结合智能的AI服务交互策略，成功构建了一个高效、稳定且可扩展的P社Mod本地化解决方案。这一架构不仅解决了性能瓶颈，也为未来集成更多AI服务和优化翻译质量奠定了坚实基础。