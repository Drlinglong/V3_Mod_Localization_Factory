# scripts/core/base_handler.py
import time
import logging
from abc import ABC, abstractmethod

from scripts.utils import i18n
from scripts.app_settings import MAX_RETRIES, FALLBACK_FORMAT_PROMPT
from scripts.core.parallel_processor import BatchTask
from scripts.utils.punctuation_handler import generate_punctuation_prompt
from scripts.core.glossary_manager import glossary_manager
from scripts.utils.structured_parser import parse_response
from scripts.utils.text_clean import mask_special_tokens
from scripts.core.prompt_manager import prompt_manager


class BaseApiHandler(ABC):
    """ã€åŸºç±»ã€‘API Handler æŠ½è±¡åŸºç±»ï¼Œå°è£…é€šç”¨é€»è¾‘ã€‚"""

    def __init__(self, provider_name: str, model_id: str = None):
        """
        é€šç”¨çš„æ„é€ å‡½æ•°ã€‚
        """
        self.provider_name = provider_name
        self.model_id = model_id
        self.logger = logging.getLogger(self.__class__.__name__)
        self.client = self.initialize_client()

    def get_provider_config(self) -> dict:
        """
        è·å–æä¾›å•†çš„é…ç½®ï¼Œåˆå¹¶é»˜è®¤é…ç½®å’Œç”¨æˆ·è¦†ç›–é…ç½®ã€‚
        """
        from scripts.app_settings import API_PROVIDERS
        from scripts.core.config_manager import config_manager
        
        base_config = API_PROVIDERS.get(self.provider_name, {}).copy()
        user_overrides = config_manager.get_value("provider_config", {}).get(self.provider_name, {})
        
        # Merge user overrides
        if user_overrides:
            # Priority: 1. Request param (self.model_id), 2. User Override, 3. Base Default
            selected_model = self.model_id or user_overrides.get("selected_model")
            available_models = base_config.get("available_models", [])
            
            # Use selected model only if it exists in the available list or is a custom model
            if selected_model:
                if selected_model in available_models:
                    base_config["default_model"] = selected_model
                else:
                    self.logger.warning(f"Selected model '{selected_model}' for provider '{self.provider_name}' is not in available list. Falling back to default: {base_config.get('default_model')}")

            if "api_url" in user_overrides and user_overrides["api_url"]:
                base_config["base_url"] = user_overrides["api_url"]
        elif self.model_id:
            # If no overrides but we have a request model, use it
            base_config["default_model"] = self.model_id
            
        return base_config

    @abstractmethod
    def initialize_client(self):
        """ã€å¿…é¡»ç”±å­ç±»å®ç°ã€‘åˆå§‹åŒ–å¹¶è¿”å›ç‰¹å®šäºè¯¥Providerçš„APIå®¢æˆ·ç«¯ã€‚"""
        pass

    @abstractmethod
    def _call_api(self, client: any, prompt: str) -> str:
        """ã€å¿…é¡»ç”±å­ç±»å®ç°ã€‘æ‰§è¡Œå¯¹ç‰¹å®šAPIçš„è°ƒç”¨å¹¶è¿”å›åŸå§‹æ–‡æœ¬å“åº”ã€‚"""
        pass

    def _build_prompt(self, task: BatchTask) -> str:
        """
        ã€é€šç”¨é€»è¾‘ã€‘æ ¹æ®ä»»åŠ¡æ„å»ºå®Œæ•´çš„ç¿»è¯‘æç¤ºã€‚
        """
        chunk = task.texts
        source_lang = task.file_task.source_lang
        target_lang = task.file_task.target_lang
        game_profile = task.file_task.game_profile
        mod_context = task.file_task.mod_context
        batch_num = task.batch_index + 1



        # Apply Token Masking (Newlines & Quotes)
        masked_chunk = [mask_special_tokens(txt) for txt in chunk]
        numbered_list = "\n".join(f'{j + 1}. "{txt}"' for j, txt in enumerate(masked_chunk))

        effective_target_lang_name = target_lang.get("custom_name", target_lang["name"]) if target_lang.get("is_shell") else target_lang["name"]

        effective_target_lang_name = target_lang.get("custom_name", target_lang["name"]) if target_lang.get("is_shell") else target_lang["name"]

        # Use PromptManager to get the effective prompt (handling overrides)
        prompt_template = prompt_manager.get_effective_prompt(game_profile["id"])
        if not prompt_template:
            # Fallback if for some reason it's missing (shouldn't happen if game_profile is valid)
            prompt_template = game_profile.get("prompt_template", "")

        base_prompt = prompt_template.format(
            source_lang_name=source_lang["name"],
            target_lang_name=effective_target_lang_name,
        )
        context_prompt_part = (
            f"CRITICAL CONTEXT: The mod you are translating is '{mod_context}'. "
            "Use this information to ensure all translations are thematically appropriate.\n"
        )

        glossary_prompt_part = ""
        if glossary_manager.get_glossary_for_translation():
            relevant_terms = glossary_manager.extract_relevant_terms(
                chunk, source_lang["code"], target_lang["code"]
            )
            if relevant_terms:
                glossary_prompt_part = glossary_manager.create_dynamic_glossary_prompt(
                    relevant_terms, source_lang["code"], target_lang["code"]
                ) + "\n\n"
                self.logger.info(i18n.t("batch_translation_glossary_injected", batch_num=batch_num, count=len(relevant_terms)))

        punctuation_prompt = generate_punctuation_prompt(
            source_lang["code"],
            target_lang["code"]
        )

        effective_format_prompt = prompt_manager.get_effective_format_prompt(game_profile["id"])
        
        if effective_format_prompt:
             format_prompt_part = effective_format_prompt.format(
                chunk_size=len(chunk),
                numbered_list=numbered_list
            )
        else:
            format_prompt_part = FALLBACK_FORMAT_PROMPT.format(
                chunk_size=len(chunk),
                numbered_list=numbered_list
            )

        punctuation_prompt_part = f"\nPUNCTUATION CONVERSION:\n{punctuation_prompt}\n" if punctuation_prompt else ""
        
        # Add a "Final Warning" section for Victoria 3 specifically
        final_warning = ""
        if game_profile["id"] == "victoria3":
            final_warning = (
                "\nğŸš¨ FINAL MANDATORY REMINDER FOR VICTORIA 3:\n"
                "- DO NOT translate the label inside [Concept('key', 'Label')]. Keep it English.\n"
                "- DO NOT translate anything inside [SCOPE...].\n"
                "- Ensure the JSON format is strictly followed.\n"
            )

        prompt = base_prompt + context_prompt_part + glossary_prompt_part + format_prompt_part + punctuation_prompt_part + final_warning
        return prompt

    def _parse_response(self, response: str, original_texts: list[str], target_lang_code: str) -> list[str] | None:
        """
        ã€é€šç”¨é€»è¾‘ã€‘è°ƒç”¨ç»“æ„åŒ–è§£æå™¨æ¥è§£æAPIå“åº”ã€‚
        -   æˆåŠŸï¼šè¿”å›ç¿»è¯‘æ–‡æœ¬åˆ—è¡¨ã€‚
        -   å¤±è´¥ï¼šè¿”å›Noneï¼Œä»¥è§¦å‘ä¸Šæ¸¸çš„é‡è¯•æœºåˆ¶ã€‚
        """

        parsed_model = parse_response(response, target_lang=target_lang_code)
        if parsed_model:
            return parsed_model.translations
        return None

    def translate_batch(self, task: BatchTask) -> BatchTask:
        """
        ã€æ ¸å¿ƒå·¥ä½œæµã€‘å¤„ç†å•ä¸ªæ‰¹æ¬¡çš„ç¿»è¯‘ä»»åŠ¡ï¼ŒåŒ…å«é‡è¯•é€»è¾‘ã€‚
        """
        prompt = self._build_prompt(task)
        batch_num = task.batch_index + 1
        start_time = time.time() # <--- æ·»åŠ æ—¶é—´è®°å½•

        for attempt in range(MAX_RETRIES):
            try:

                raw_response = self._call_api(self.client, prompt)
                translated_texts = self._parse_response(raw_response, task.texts, task.file_task.target_lang["code"])

                # Check for success: must not be None, must not be the original list, and length must match.
                if translated_texts is not None and translated_texts is not task.texts and len(translated_texts) == len(task.texts):
                    task.translated_texts = translated_texts
                    elapsed_time = time.time() - start_time # <--- è®¡ç®—è€—æ—¶
                    self.logger.info(i18n.t("batch_success", batch_num=batch_num, attempt=attempt + 1, elapsed_time=elapsed_time)) # <--- ä¼ é€’å‚æ•°
                    return task
                else:
                    self.logger.warning(
                        f"Response parsing failed for batch {batch_num} on attempt {attempt + 1}. "
                        f"Expected {len(task.texts)} items, got {len(translated_texts) if translated_texts else 0}."
                    )
                    raise ValueError("Response parsing failed, triggering retry.")

            except Exception as e:
                self.logger.exception(f"API call failed for batch {batch_num} on attempt {attempt + 1}: {e}")

            if attempt < MAX_RETRIES - 1:
                delay = (attempt + 1) * 2
                self.logger.warning(i18n.t("retrying_batch", batch_num=batch_num, attempt=attempt + 1, max_retries=MAX_RETRIES, delay=delay))
                time.sleep(delay)

        self.logger.error(f"Batch {batch_num} failed after {MAX_RETRIES} attempts. Falling back to original texts.")
        task.failed = True
        task.translated_texts = task.texts
        # We still return the task object so the aggregator can see it failed but has text
        return task

    def _build_single_text_prompt(self, text: str, task_description: str, mod_name: str, source_lang: dict, target_lang: dict, mod_context: str, game_profile: dict) -> str:
        """ã€é€šç”¨é€»è¾‘ã€‘ä¸ºå•æ¡æ–‡æœ¬æ„å»ºä¸“ç”¨çš„ç¿»è¯‘æç¤ºã€‚"""
        base_prompt = game_profile["single_prompt_template"].format(
            mod_name=mod_name,
            task_description=task_description,
            source_lang_name=source_lang["name"],
            target_lang_name=target_lang["name"],
        )

        glossary_prompt_part = ""
        if glossary_manager.get_glossary_for_translation():
            relevant_terms = glossary_manager.extract_relevant_terms(
                [text], source_lang["code"], target_lang["code"]
            )
            if relevant_terms:
                glossary_prompt_part = glossary_manager.create_dynamic_glossary_prompt(
                    relevant_terms, source_lang["code"], target_lang["code"]
                ) + "\n\n"

        punctuation_prompt = generate_punctuation_prompt(
            source_lang["code"],
            target_lang["code"]
        )

        # Apply masking to the single text as well
        masked_text = mask_special_tokens(text)

        prompt = (
            base_prompt
            + f"CRITICAL CONTEXT: The mod's theme is '{mod_context}'. Use this to ensure accuracy.\n"
            + glossary_prompt_part
            + "CRITICAL FORMATTING: Your response MUST ONLY contain the translated text. "
            "DO NOT include explanations, pinyin, or any other text.\n"
            'For example, if the input is "Flavor Pack", your output must be "é£å‘³åŒ…" and nothing else.\n\n'
            + (f"PUNCTUATION CONVERSION:\n{punctuation_prompt}\n\n" if punctuation_prompt else "")
            + f'Translate this: "{masked_text}"'
        )
        return prompt

    def translate_single_text(self, text: str, task_description: str, mod_name: str, source_lang: dict, target_lang: dict, mod_context: str, game_profile: dict) -> str:
        """ã€é€šç”¨å·¥ä½œæµã€‘ç¿»è¯‘å•æ¡æ–‡æœ¬ï¼Œå¸¦ä¸€æ¬¡è°ƒç”¨ï¼Œå¤±è´¥åˆ™è¿”å›åŸæ–‡ã€‚"""
        if not text:
            return ""

        prompt = self._build_single_text_prompt(text, task_description, mod_name, source_lang, target_lang, mod_context, game_profile)

        try:
            raw_response = self._call_api(self.client, prompt)
            # Simple cleanup for single text
            translated_text = raw_response.strip().strip('"')
            
            # Restore tokens
            from scripts.utils.text_clean import restore_special_tokens
            translated_text = restore_special_tokens(translated_text, target_lang["code"])
            
            return translated_text
        except Exception as e:
            self.logger.exception(f"Single text translation failed for '{text[:30]}...': {e}")
            return text # Fallback to original text

    def generate_with_messages(self, messages: list[dict], temperature: float = 0.7) -> str:
        """
        ã€é€šç”¨é€»è¾‘ã€‘æ”¯æŒåŸºäºæ¶ˆæ¯çš„å¯¹è¯ç”Ÿæˆã€‚
        é»˜è®¤å®ç°å°†æ¶ˆæ¯æ‹¼æ¥ä¸ºå•ä¸ª Promptï¼Œè°ƒç”¨ _call_apiã€‚
        å­ç±»ï¼ˆå¦‚ OpenAIHandlerï¼‰å¯ä»¥è¦†ç›–æ­¤æ–¹æ³•ä»¥ä½¿ç”¨åŸç”Ÿ Chat æ¥å£ã€‚
        """
        system_instruction = ""
        user_content = ""
        
        for msg in messages:
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            if role == 'system':
                system_instruction = content
            elif role == 'user':
                user_content += content + "\n"
        
        full_prompt = user_content
        if system_instruction:
            full_prompt = f"{system_instruction}\n\n{user_content}"
            
        try:
            # ä½¿ç”¨ _call_apiï¼Œè¿™æ„å‘³ç€æ‰€æœ‰å®ç°äº† _call_api çš„å­ç±»éƒ½è‡ªåŠ¨æ”¯æŒæ­¤åŠŸèƒ½
            return self._call_api(self.client, full_prompt)
        except Exception as e:
            self.logger.exception(f"Generate with messages failed: {e}")
            return ""

