# scripts/core/glossary_manager.py
import os
import json
import logging
import re
from typing import Dict, List, Set, Optional, Tuple
from scripts.config import PROJECT_ROOT


class GlossaryManager:
    """æ¸¸æˆä¸“ç”¨è¯å…¸ç®¡ç†å™¨"""
    
    def __init__(self):
        self.glossaries: Dict[str, Dict] = {}
        self.current_game_glossary: Optional[Dict] = None
        self.current_game_id: Optional[str] = None
        self.current_auxiliary_glossaries: List[Dict] = []  # å¤–æŒ‚è¯å…¸åˆ—è¡¨
        self.merged_glossary: Optional[Dict] = None  # åˆå¹¶åçš„è¯å…¸
        
    def scan_auxiliary_glossaries(self, game_id: str) -> List[Dict]:
        """
        æ‰«ææŒ‡å®šæ¸¸æˆç›®å½•ä¸‹çš„å¤–æŒ‚è¯å…¸
        
        Args:
            game_id: æ¸¸æˆID
            
        Returns:
            List[Dict]: å¤–æŒ‚è¯å…¸ä¿¡æ¯åˆ—è¡¨
        """
        glossary_dir = os.path.join(PROJECT_ROOT, 'data', 'glossary', game_id)
        if not os.path.exists(glossary_dir):
            return []
            
        auxiliary_glossaries = []
        
        for filename in os.listdir(glossary_dir):
            if filename.endswith('.json') and filename != 'glossary.json':
                file_path = os.path.join(glossary_dir, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        glossary_data = json.load(f)
                        
                    # æå–è¯å…¸ä¿¡æ¯
                    metadata = glossary_data.get('metadata', {})
                    auxiliary_glossaries.append({
                        'filename': filename,
                        'file_path': file_path,
                        'name': metadata.get('name', filename.replace('.json', '')),
                        'description': metadata.get('description', ''),
                        'entry_count': len(glossary_data.get('entries', [])),
                        'data': glossary_data
                    })
                except Exception as e:
                    logging.warning(f"Failed to load auxiliary glossary {filename}: {e}")
                    
        return auxiliary_glossaries
    
    def load_game_glossary(self, game_id: str) -> bool:
        """
        åŠ è½½æŒ‡å®šæ¸¸æˆçš„ä¸»è¯å…¸æ–‡ä»¶
        
        Args:
            game_id: æ¸¸æˆID (å¦‚ 'victoria3', 'stellaris')
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½
        """
        if game_id == self.current_game_id and self.current_game_glossary:
            return True
            
        glossary_path = os.path.join(PROJECT_ROOT, 'data', 'glossary', game_id, 'glossary.json')
        
        try:
            if os.path.exists(glossary_path):
                with open(glossary_path, 'r', encoding='utf-8') as f:
                    self.current_game_glossary = json.load(f)
                    self.current_game_id = game_id
                    from scripts.utils import i18n
                    logging.info(i18n.t("glossary_loaded_success", 
                                      game_id=game_id, 
                                      count=len(self.current_game_glossary.get('entries', []))))
                    return True
            else:
                from scripts.utils import i18n
                logging.warning(i18n.t("glossary_file_not_found", path=glossary_path))
                self.current_game_glossary = None
                self.current_game_id = game_id
                return False
                
        except Exception as e:
            from scripts.utils import i18n
            logging.error(i18n.t("glossary_load_failed", error=str(e)))
            self.current_game_glossary = None
            self.current_game_id = game_id
            return False
    
    def has_any_glossary(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¯ç”¨çš„è¯å…¸ï¼ˆä¸»è¯å…¸æˆ–å¤–æŒ‚è¯å…¸ï¼‰
        
        Returns:
            bool: æ˜¯å¦æœ‰ä»»ä½•è¯å…¸å¯ç”¨
        """
        return (self.current_game_glossary is not None or 
                len(self.current_auxiliary_glossaries) > 0 or 
                self.merged_glossary is not None)
    
    def get_glossary_status_summary(self) -> str:
        """
        è·å–è¯å…¸çŠ¶æ€æ‘˜è¦
        
        Returns:
            str: è¯å…¸çŠ¶æ€æè¿°
        """
        if not self.current_game_id:
            return "æœªåŠ è½½ä»»ä½•è¯å…¸"
            
        if self.merged_glossary:
            main_count = len(self.current_game_glossary.get('entries', [])) if self.current_game_glossary else 0
            aux_count = len(self.current_auxiliary_glossaries)
            total_count = len(self.merged_glossary.get('entries', []))
            return f"ä¸»è¯å…¸({main_count}æ¡) + å¤–æŒ‚è¯å…¸({aux_count}ä¸ª) = æ€»è®¡({total_count}æ¡)"
        elif self.current_game_glossary:
            count = len(self.current_game_glossary.get('entries', []))
            return f"ä»…ä¸»è¯å…¸({count}æ¡)"
        elif self.current_auxiliary_glossaries:
            aux_count = len(self.current_auxiliary_glossaries)
            return f"ä»…å¤–æŒ‚è¯å…¸({aux_count}ä¸ª)"
        else:
            return "æ— å¯ç”¨è¯å…¸"
    
    def load_auxiliary_glossaries(self, selected_indices: List[int]) -> bool:
        """
        åŠ è½½é€‰ä¸­çš„å¤–æŒ‚è¯å…¸
        
        Args:
            selected_indices: é€‰ä¸­çš„å¤–æŒ‚è¯å…¸ç´¢å¼•åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½
        """
        if not self.current_game_id:
            return False
            
        auxiliary_glossaries = self.scan_auxiliary_glossaries(self.current_game_id)
        self.current_auxiliary_glossaries = []
        
        for idx in selected_indices:
            if 0 <= idx < len(auxiliary_glossaries):
                self.current_auxiliary_glossaries.append(auxiliary_glossaries[idx])
                
        # åˆå¹¶è¯å…¸
        self._merge_glossaries()
        return True
    
    def _merge_glossaries(self):
        """åˆå¹¶ä¸»è¯å…¸å’Œå¤–æŒ‚è¯å…¸"""
        if not self.current_game_glossary:
            self.merged_glossary = None
            return
            
        # æ·±æ‹·è´ä¸»è¯å…¸
        merged = json.loads(json.dumps(self.current_game_glossary))
        merged_entries = merged.get('entries', [])
        
        # æ·»åŠ å¤–æŒ‚è¯å…¸æ¡ç›®
        for aux_glossary in self.current_auxiliary_glossaries:
            aux_entries = aux_glossary['data'].get('entries', [])
            for entry in aux_entries:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„æ¡ç›®
                existing_entry = next((e for e in merged_entries if e.get('id') == entry.get('id')), None)
                if existing_entry:
                    # å¦‚æœå­˜åœ¨ï¼Œå¤–æŒ‚è¯å…¸çš„æ¡ç›®ä¼˜å…ˆçº§æ›´é«˜
                    existing_entry.update(entry)
                else:
                    # å¦‚æœä¸å­˜åœ¨ï¼Œç›´æ¥æ·»åŠ 
                    merged_entries.append(entry)
                    
        self.merged_glossary = merged
        
        # è®°å½•åˆå¹¶ç»“æœ
        total_entries = len(merged_entries)
        main_entries = len(self.current_game_glossary.get('entries', []))
        aux_entries = total_entries - main_entries
        
        from scripts.utils import i18n
        if i18n.get_current_language() == "en_US":
            logging.info(f"Glossary merged: {main_entries} main entries + {aux_entries} auxiliary entries = {total_entries} total")
        else:
            logging.info(f"è¯å…¸åˆå¹¶å®Œæˆ: {main_entries} ä¸ªä¸»è¯å…¸æ¡ç›® + {aux_entries} ä¸ªå¤–æŒ‚è¯å…¸æ¡ç›® = {total_entries} ä¸ªæ€»è®¡")
    
    def get_glossary_for_translation(self) -> Optional[Dict]:
        """è·å–ç”¨äºç¿»è¯‘çš„è¯å…¸ï¼ˆä¼˜å…ˆä½¿ç”¨åˆå¹¶åçš„è¯å…¸ï¼‰"""
        return self.merged_glossary if self.merged_glossary else self.current_game_glossary
    
    def extract_relevant_terms(self, texts: List[str], source_lang: str, target_lang: str) -> List[Dict]:
        """
        ä»å¾…ç¿»è¯‘æ–‡æœ¬ä¸­æå–ç›¸å…³çš„è¯å…¸æœ¯è¯­ï¼ˆæ”¯æŒåŒå‘ç¿»è¯‘ï¼‰
        
        Args:
            texts: å¾…ç¿»è¯‘çš„æ–‡æœ¬åˆ—è¡¨
            source_lang: æºè¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            List[Dict]: ç›¸å…³æœ¯è¯­åˆ—è¡¨
        """
        glossary = self.get_glossary_for_translation()
        if not glossary:
            return []
            
        relevant_terms = []
        all_text = " ".join(texts).lower()
        
        for entry in glossary.get('entries', []):
            translations = entry.get('translations', {})
            source_term = translations.get(source_lang, "")
            target_term = translations.get(target_lang, "")
            
            if not source_term or not target_term:
                continue
                
            # æ£€æŸ¥æºæœ¯è¯­æ˜¯å¦åœ¨å¾…ç¿»è¯‘æ–‡æœ¬ä¸­å‡ºç°ï¼ˆæ”¯æŒåŒå‘è¯†åˆ«ï¼‰
            if self._term_appears_in_text(source_term, all_text, source_lang):
                relevant_terms.append({
                    'translations': {
                        source_lang: source_term,
                        target_lang: target_term
                    },
                    'id': entry.get('id', ''),
                    'metadata': entry.get('metadata', {}),
                    'variants': entry.get('variants', {})
                })
                
        # æŒ‰æœ¯è¯­é•¿åº¦æ’åºï¼Œä¼˜å…ˆå¤„ç†è¾ƒé•¿çš„æœ¯è¯­
        relevant_terms.sort(key=lambda x: len(x['translations'][source_lang]), reverse=True)
        
        from scripts.utils import i18n
        logging.info(i18n.t("glossary_terms_extracted", 
                           count=len(relevant_terms), 
                           text_count=len(texts)))
        return relevant_terms
    
    def _term_appears_in_text(self, term: str, text: str, source_lang: str) -> bool:
        """
        æ£€æŸ¥æœ¯è¯­æ˜¯å¦åœ¨æ–‡æœ¬ä¸­å‡ºç°ï¼ˆæ”¯æŒå˜ä½“å’Œå¤šè¯­è¨€ï¼‰
        
        Args:
            term: æœ¯è¯­
            text: æ–‡æœ¬
            source_lang: æºè¯­è¨€ä»£ç 
            
        Returns:
            bool: æ˜¯å¦å‡ºç°
        """
        # ç›´æ¥åŒ¹é…
        if term.lower() in text:
            return True
            
        # æ£€æŸ¥å˜ä½“ï¼ˆæ”¯æŒå¤šè¯­è¨€å˜ä½“ï¼‰
        glossary = self.get_glossary_for_translation()
        if glossary:
            for entry in glossary.get('entries', []):
                if entry.get('translations', {}).get(source_lang, '').lower() == term.lower():
                    variants = entry.get('variants', {}).get(source_lang, [])
                    for variant in variants:
                        if variant.lower() in text:
                            return True
                            
        return False
    
    def create_dynamic_glossary_prompt(self, relevant_terms: List[Dict], source_lang: str, target_lang: str) -> str:
        """
        åˆ›å»ºåŠ¨æ€è¯å…¸æç¤ºï¼Œç”¨äºæ³¨å…¥åˆ°AIç¿»è¯‘è¯·æ±‚ä¸­
        
        Args:
            relevant_terms: ç›¸å…³æœ¯è¯­åˆ—è¡¨
            source_lang: æºè¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            str: æ ¼å¼åŒ–çš„è¯å…¸æç¤º
        """
        if not relevant_terms:
            return ""
            
        prompt_lines = [
            "ğŸ” CRITICAL GLOSSARY INSTRUCTIONS - HIGH PRIORITY ğŸ”",
            f"ä»¥ä¸‹æœ¯è¯­å¿…é¡»ä¸¥æ ¼æŒ‰ç…§è¯å…¸ç¿»è¯‘ï¼Œä¿æŒæ¸¸æˆæœ¯è¯­çš„ä¸€è‡´æ€§ï¼š",
            "",
            "æœ¯è¯­å¯¹ç…§è¡¨ï¼š"
        ]
        
        for term in relevant_terms:
            source = term['translations'][source_lang]
            target = term['translations'][target_lang]
            metadata = term.get('metadata', {})
            remarks = metadata.get('remarks', '')
            
            prompt_lines.append(f"â€¢ '{source}' â†’ '{target}'")
            if remarks:
                prompt_lines.append(f"  å¤‡æ³¨: {remarks}")
                
        prompt_lines.extend([
            "",
            "ç¿»è¯‘è¦æ±‚ï¼š",
            "1. ä¸Šè¿°æœ¯è¯­å¿…é¡»ä¸¥æ ¼æŒ‰ç…§è¯å…¸ç¿»è¯‘ï¼Œä¸å¾—éšæ„æ›´æ”¹",
            "2. ä¿æŒæ¸¸æˆæœ¯è¯­çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§",
            "3. æœ¯è¯­åœ¨å¥å­ä¸­çš„ä½ç½®åº”è¯¥è‡ªç„¶ã€æ°å½“",
            "4. å¦‚æœé‡åˆ°è¯å…¸ä¸­æœªåŒ…å«çš„æœ¯è¯­ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡è¿›è¡Œåˆç†ç¿»è¯‘",
            "",
            "è¯·ç¡®ä¿åœ¨ç¿»è¯‘è¿‡ç¨‹ä¸­ä¸¥æ ¼éµå¾ªä»¥ä¸Šæœ¯è¯­å¯¹ç…§è¡¨ã€‚"
        ])
        
        return "\n".join(prompt_lines)
    
    def get_glossary_stats(self) -> Dict:
        """
        è·å–å½“å‰åŠ è½½è¯å…¸çš„ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        if not self.current_game_glossary:
            return {"loaded": False, "game_id": self.current_game_id}
            
        entries = self.current_game_glossary.get('entries', [])
        metadata = self.current_game_glossary.get('metadata', {})
        
        return {
            "loaded": True,
            "game_id": self.current_game_id,
            "total_entries": len(entries),
            "description": metadata.get('description', ''),
            "last_updated": metadata.get('last_updated', ''),
            "sources": metadata.get('sources', []),
            "auxiliary_count": len(self.current_auxiliary_glossaries)
        }
    
    def get_auxiliary_glossaries_info(self) -> List[Dict]:
        """è·å–å¤–æŒ‚è¯å…¸ä¿¡æ¯åˆ—è¡¨"""
        if not self.current_game_id:
            return []
        return self.scan_auxiliary_glossaries(self.current_game_id)


# å…¨å±€è¯å…¸ç®¡ç†å™¨å®ä¾‹
glossary_manager = GlossaryManager()
