2025-08-12 18:15:38,198 - INFO - Logger initialized and ready.
2025-08-12 18:15:40,524 - INFO - 语言已设置为 zh_CN。
2025-08-12 18:15:40,524 - INFO - --- New Session Started ---
2025-08-12 18:15:45,278 - INFO - <scan_source_folder>
2025-08-12 18:15:45,278 - INFO - <select_mod_prompt>
2025-08-12 18:15:45,278 - INFO -   [1] Australia & New Zealand Flavor Pack
2025-08-12 18:15:45,278 - INFO -   [2] Forts & Engineers
2025-08-12 18:15:45,278 - INFO -   [3] GORA UI
2025-08-12 18:15:45,278 - INFO -   [4] Hydra's More Agenda's
2025-08-12 18:15:45,278 - INFO -   [5] MODJAM2025
2025-08-12 18:15:45,279 - INFO -   [6] MODJAM2025 - 副本
2025-08-12 18:15:45,279 - INFO -   [7] Offer Convoy Contribution
2025-08-12 18:15:45,279 - INFO -   [8] Project Utopia - Extended Timeline - Technical Preview
2025-08-12 18:15:45,279 - INFO -   [9] Tech & Res
2025-08-12 18:15:45,279 - INFO -   [10] TEST-ANZAC
2025-08-12 18:15:45,279 - INFO -   [11] UKrework
2025-08-12 18:15:47,483 - INFO - <you_selected>
2025-08-12 18:15:47,484 - INFO - 
--- 正在获取Mod主题上下文 ---
2025-08-12 18:15:47,484 - INFO - 已识别Mod名称为: 'Offer Convoy Contribution'
2025-08-12 18:15:52,738 - INFO - 最终使用的主题上下文为: 'Offer Convoy Contribution'
2025-08-12 18:15:52,739 - INFO - <cleanup_start>
2025-08-12 18:15:55,675 - INFO - <cleanup_deleting>
2025-08-12 18:15:55,676 - INFO - <cleanup_success>
2025-08-12 18:16:06,447 - INFO - 
--- 启动 '首次翻译' 工作流，目标: Offer Convoy Contribution ---
2025-08-12 18:16:06,620 - INFO - OpenAI client initialized successfully, using model: gpt-5
2025-08-12 18:16:06,620 - INFO - <processing_metadata>
2025-08-12 18:16:06,620 - INFO - <translating_mod_name>
2025-08-12 18:16:07,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-12 18:16:07,265 - ERROR - <api_call_error>
Traceback (most recent call last):
  File "J:\V3_Mod_Localization_Factory\scripts\core\openai_handler.py", line 64, in translate_single_text
    response = client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-12 18:16:07,267 - INFO - <metadata_success>
2025-08-12 18:16:07,267 - INFO - <processing_assets>
2025-08-12 18:16:07,268 - INFO - <asset_copied>
2025-08-12 18:16:07,268 - INFO - <parsing_file>
2025-08-12 18:16:07,269 - INFO - 
--- 正在翻译为: 简体中文 ---
2025-08-12 18:16:07,683 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-12 18:16:07,683 - ERROR - <api_call_error>
Traceback (most recent call last):
  File "J:\V3_Mod_Localization_Factory\scripts\core\openai_handler.py", line 115, in _translate_chunk
    response = client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-12 18:16:07,684 - WARNING - <retrying_batch>
2025-08-12 18:16:09,973 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-12 18:16:09,973 - ERROR - <api_call_error>
Traceback (most recent call last):
  File "J:\V3_Mod_Localization_Factory\scripts\core\openai_handler.py", line 115, in _translate_chunk
    response = client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-12 18:16:09,974 - WARNING - <retrying_batch>
2025-08-12 18:16:14,226 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-08-12 18:16:14,226 - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-08-12 18:16:34,606 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-08-12 18:16:34,606 - ERROR - <api_call_error>
Traceback (most recent call last):
  File "J:\V3_Mod_Localization_Factory\scripts\core\openai_handler.py", line 115, in _translate_chunk
    response = client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1249, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Drlin\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1037, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-12 18:16:34,607 - INFO - <creating_fallback_file>
2025-08-12 18:16:34,607 - INFO - <fallback_file_created>
2025-08-12 18:16:34,608 - INFO - 工作流完成！
